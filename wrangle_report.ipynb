{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The wrangling process involves four(4) stages\n",
    "- Gathering Data\n",
    "- Acessing Data\n",
    "- Cleaning Data\n",
    "- Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gathering Data:\n",
    "This section require three pieces of dataset to be gathered:\n",
    "- twitter_archive_enhanced.csv\n",
    "> This dataset is a csv file downloaded manually from the link given [`twitter_archive_enhanced.csv`](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv)\n",
    "- image_predictions.tsv\n",
    "> This dataset was downloaded using python request library from the url: [`image_predictions.tsv`](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv)\n",
    "\n",
    "- tweet_json.txt\n",
    "> This dataset is a txt file gotten from the supporting material section provided by Udacity [`tweet_json.txt`](https://video.udacity-data.com/topher/2018/November/5be5fb7d_tweet-json/tweet-json.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Accessing Data:\n",
    "Each dataset gathered were read individually using python library tool Pandas. This enabled the datasets to be accessed both visually and programmatically. \n",
    "\n",
    "During the accessment for each dataset, the following issues were observed.\n",
    "\n",
    "`Quality Issues:`\n",
    "\n",
    "1. Erroneous datatype : 'tweet_id' in all three tables and 'timestamp' in archived table\n",
    "\n",
    "#####  archived table\n",
    "2. Retweets are presents: Only original ratings (no retweets) that have images should be considered\n",
    "3. Missing information (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp)\n",
    "4. The column 'source' has unnecessary html tags.\n",
    "5. The column 'name' has inaccurate values starting with lowercase letters : a, an, all, the, mad, not by etc, instead of 'None'\n",
    "6. The column 'expanded_urls' has null values\n",
    "7. urls links at the end of the column 'text'\n",
    "\n",
    "#####  image_df table\n",
    "8. Drop unnecessary columns and give p1 a better names.\n",
    "\n",
    "`Tidiness issues:`\n",
    "\n",
    "9. Redundant columns of the same category, ['doggo', 'flooter', 'pupper', 'puppo'] columns, but we only need one 'stage' column\n",
    "10. \"retweet count\" and \"favorite count\" columns are not in the archived\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cleaning Data:\n",
    "**FIRST STEP:** I made a copy of three dataframes using pandas function `.copy()`\n",
    "- archived_clean = archived.copy()\n",
    "- image_df_clean = image_df.copy()\n",
    "- retweet_df_clean = retweet_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUTHER STEPS:**\n",
    "###### For archived table\n",
    "- I converted 'tweet_id' in all three tables from int to string and 'timestamp' to pandas datetime in archived table\n",
    "- I dropped the rows with values present in in_reply_to_status_id and retweeted_status_id columns\n",
    "- I dropped the columns (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp)\n",
    "- I used BeautifulSoup on the 'source' column to get the texts from the tag \n",
    "- I replaced names starting with lowercase letters with 'None' \n",
    "- I dropped null values in expanded_urls\n",
    "- I removed the url link at the end of the each tweet for the column 'text'\n",
    "\n",
    "###### For image_df table\n",
    "- I dropped columns (p2, p2_conf, p2_dog, p3, p3_conf, p3_dog) and renamed p1, p1_conf, p1_dog to breed, onfidence and results respectively.\n",
    "\n",
    "###### For Tidiness issues\n",
    "- In archived_clean table, I created a new column named 'stage' and catergorise it based on doggo, flooter, pupper, puppo.\n",
    "- In archived_clean table, I dropped ['doggo', 'flooter', 'pupper', 'puppo'] columns\n",
    "- I merged retweet_df with archived_df_clean to give merged_df1_clean\n",
    "- Lastly I merged merged_df1 with image_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>ðŸ›  Issues and solutions</summary>\n",
    "\n",
    "| **Issues no**   | **Solution** |\n",
    "| ----------- | ----------- |\n",
    "| 1 | Convert 'tweet_id' in all three tables from int to string and 'timestamp' to pandas datetime in archived table |\n",
    "| 2 |  Drop observations reply and retweet, by deleting the rows with values present in in_reply_to_status_id and retweeted_status_id columns  |\n",
    "| 3 | Drop the columns (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp) |\n",
    "| 4 | Use BeautifulSoup to get the texts from the tag |\n",
    "| 5 | Replace names starting with lowercase letters with 'None' |\n",
    "| 6 | Drop null values in expanded_urls |\n",
    "| 7 | Removed the url link at the end of the each tweet for the column 'text' |\n",
    "| 8 | Drop p2, p2_conf, p2_dog, p3, p3_conf, p3_dog and rename p1, p1_conf, p1_dog |\n",
    "| 9 | Create new column 'stage', catergorise it based on doggo, flooter, pupper, puppo and lastly drop ['doggo', 'flooter', 'pupper', 'puppo'] columns |\n",
    "| 10 | Merge retweet_df with archived_df |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing Data:\n",
    "- The clean data was stored to a csv file named 'twitter_archive_master.csv' by using pandas function `.to_csv()`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
